\chapter{Introduction}

In recent years, artificial neural networks have become increasingly important, powering many popular applications such as speech recognition (\cite{deng_new_2013}), image recognition (\cite{rowley_neural_1998}), and machine translation (\cite{zhang_deep_2015,bengio_practical_2012}). Artificial neural networks are a subset of machine learning, another subset of which is reinforcement learning, a field that is far less popular (\cite{jordan_machine_2015}).

Nevertheless, significant progress has been made in reinforcement learning, exemplified by AlphaGo, which defeated the world champion in Go in 2016, and AlphaGo Zero, which surpassed human performance after only 24 hours of training (\cite{google_deepmind_alphago_2020,silver_mastering_2016,silver_mastering_2017}.) The entry into reinforcement learning is relatively simple thanks to numerous videos and tutorials available online, as well as many libraries (such as OpenAI Gym) that facilitate the implementation of reinforcement learning algorithms (\cite{nicholas_renotte_reinforcement_2021,raffin_stable-baselines3_2024,sentdex_q_2019}). The book \textit{Reinforcement Learning: An Introduction} by Sutton and Barto is a standard work in this field, offering a comprehensive introduction to the subject. It is also available under a Creative Commons license, making it freely accessible (\cite{sutton_reinforcement_2018}).

One of the standard examples in the literature is the cart-pole problem, where a cart must balance a pole attached to it. This problem is also covered in many videos and tutorials online (\cite{sutton_reinforcement_2018}). The problem is implemented in OpenAI Gym, making it easy to use and experiment with, allowing for the training of a reinforcement learning agent to solve the cart-pole problem with just a few lines of code. The use of the Stable Baselines 3 library simplifies this further by providing many pre-implemented reinforcement learning algorithms, including Proximal Policy Optimization (PPO), which has been successfully applied in many reinforcement learning applications (\cite{arxiv_insights_introduction_2018}).

However, the environment implemented by OpenAI is only simulated, making it easy to reset the pendulum to the upright position. When solving the cart-pole problem in reality, one must manually reset the pendulum to the upright position after each unsuccessful attempt, significantly extending the training process. To accelerate the training process, it is necessary to develop a reinforcement learning agent that can swing the pendulum from the downward position to the upright position, thereby addressing the cart-pole swing-up problem or the inverted pendulum problem in reality.

There are few studies in the literature that address this problem in real-world settings, with most using simple reward functions and simulated environments that do not present the real challenges of solving the problem in reality. This work focuses on developing a reinforcement learning agent that solves the swing-up cart-pole problem in reality, using a realistic environment based on a Raspberry Pi and a real cart and pendulum. It describes the challenges encountered in developing such a system, the solutions found to overcome these challenges, and future research directions to further improve the system.